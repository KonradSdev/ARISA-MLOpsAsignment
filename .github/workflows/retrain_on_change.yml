name: Preproc data and train model

on: 
  push:
    branches:
      - main
    paths:  # (re)train when train data changes or when the preproc or train code changes
      - 'data/raw/train.csv'
      - 'data/processed/train.csv'
      - 'DSML/preproc.py'
      - 'DSML/train.py'
      - 'DSML/config.py'
      - 'models/best_params.pkl'  # model should also be retrained after hyperparam tuning is run
      - 'requirements.txt' # retrain model whenever libraries are updated (to fix conflicts)

jobs:
  preprocess:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"
      - name: Install dependencies
        run: make requirements
      - name: Create kaggle directory
        env: 
          KAGGLE_KEY: ${{ secrets.KAGGLE_API_KEY }}
        run: |
          mkdir -p $HOME/.config
          mkdir -p $HOME/.config/kaggle
          echo "$KAGGLE_KEY" > $HOME/.config/kaggle/kaggle.json
          chmod 600 $HOME/.config/kaggle/kaggle.json
      - name: Run preprocessing
        run: make preprocess
      - name: Upload preprocessed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed
  train:
    runs-on: ubuntu-latest
    needs: preprocess
    permissions:
      contents: write  # This gives the token write access to the repository contents
      actions: write   # âœ… Allows triggering other workflows!
    steps: 
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed
      - name: Set up Python
        uses: actions/setup-python@v4
        with: 
          python-version: "3.11"
      - name: Install dependencies
        run: make requirements
      - name: Run training
        env: 
          MLFLOW_TRACKING_URI: postgresql://${{secrets.MLFLOWDBUSERNAME}}:${{secrets.MLFLOWDBPASS}}@${{secrets.MLFLOWDBENDPOINT}}:${{secrets.MLFLOWDBPORT}}/${{secrets.MLFLOWDB}}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          MLFLOW_S3_ENDPOINT_URL: s3://${{secrets.ARTIFACT_BUCKET}}/models
        run: make train

      - name: Upload trained model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/

      - name: Trigger Predict Workflow
        run: |
          curl -X POST -H "Authorization: Bearer ${{ secrets.GH_TOKEN }}" \
          -H "Accept: application/vnd.github.v3+json" \
          https://api.github.com/repos/${{ github.repository }}/actions/workflows/predict_on_model_change.yml/dispatches \
          -d '{"ref":"main"}'
